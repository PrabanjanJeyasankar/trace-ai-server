# -----------------------------
# Server Configuration
# -----------------------------
NODE_ENV=production
PORT=3000

# -----------------------------
# Database
# -----------------------------
MONGO_URI=mongodb+srv://<username>:<password>@<cluster>/<database>
MONGO_URL=mongodb+srv://<username>:<password>@<cluster>/<database>

# -----------------------------
# Authentication
# -----------------------------
JWT_SECRET=your_jwt_secret_here
ACCESS_TOKEN_EXPIRY=30s
REFRESH_TOKEN_EXPIRY=1m

# Evaluation API Key (for /api/v1/eval routes)
EVAL_API_KEY=your-secure-eval-api-key-here
EVAL_USER_ID=your-eval-user-mongodb-id-here

# -----------------------------
# CORS
# -----------------------------
CORS_ORIGIN=*

# -----------------------------
# Logging
# -----------------------------
LOG_LEVEL=info

# -----------------------------
# Vector DB
# -----------------------------
QDRANT_URL=http://qdrant:6333

# -----------------------------
# AI Provider
# -----------------------------
AI_PROVIDER=openai

# OpenAI Configuration (for LLM responses)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo

# Ollama Configuration
OLLAMA_BASE_URL=http://host.docker.internal:11434
OLLAMA_MODEL=llama3.1:8b

# -----------------------------
# Redis
# -----------------------------
# When set, chat history is cached per chatId (session) in Redis for fast fetches.
# Local (running server on your machine): `redis://localhost:6379`
# Docker Compose (server container -> redis container): `redis://redis:6379`
REDIS_URL=redis://localhost:6379
CHAT_HISTORY_CACHE_TTL_SECONDS=3600
CHAT_HISTORY_CACHE_MAX_MESSAGES=200
CHAT_HISTORY_IN_MEMORY_MAX_CHATS=200

# -----------------------------
# Local Reranker (Optional but recommended for best RAG accuracy)
# -----------------------------
# Protocol: rest or rpc (default: rest)
RERANKER_PROTOCOL=rpc
# REST endpoint
# Local (running server on your machine): http://localhost:8000/rerank
# Docker Compose (server container -> reranker container): http://reranker:8000/rerank
RERANKER_URL=http://localhost:8000/rerank
# RPC endpoint (JSON-RPC 2.0) - preferred for lower latency
RERANKER_RPC_URL=http://localhost:8000/rpc
RERANKER_MODEL=BAAI/bge-reranker-base

# -----------------------------
# Embedding Service (Required for vector search)
# -----------------------------
# RPC endpoint (JSON-RPC 2.0)
# Local (running server on your machine): http://localhost:8001/rpc
# Docker Compose (server container -> embedding container): http://embedding:8001/rpc
EMBEDDING_RPC_URL=http://localhost:8001/rpc
EMBEDDING_MODEL=BAAI/bge-small-en-v1.5
OUTPUT_DIM=384

# -----------------------------
# Performance Tuning (Optional)
# -----------------------------
# Number of CPU threads for ML inference (auto-detected if not set)
# Set this to limit CPU usage or optimize for your server's core count
# Example: For a 16-core server, you might set OMP_NUM_THREADS=12
# OMP_NUM_THREADS=auto
