# -----------------------------
# Server Configuration
# -----------------------------
NODE_ENV=production
PORT=3000

# -----------------------------
# Database
# -----------------------------
MONGO_URI=mongodb+srv://<username>:<password>@<cluster>/<database>

# -----------------------------
# Authentication
# -----------------------------
JWT_SECRET=your_jwt_secret_here

# -----------------------------
# CORS
# -----------------------------
CORS_ORIGIN=*

# -----------------------------
# Logging
# -----------------------------
LOG_LEVEL=info

# -----------------------------
# Vector DB
# -----------------------------
QDRANT_URL=http://qdrant:6333

# -----------------------------
# AI Provider
# -----------------------------
AI_PROVIDER=ollama

# Gemini Configuration
GEMINI_API_KEY=your_google_api_key_here
GEMINI_MODEL=gemini-2.5-flash-lite

# Ollama Configuration
OLLAMA_BASE_URL=http://host.docker.internal:11434
OLLAMA_MODEL=llama3.1:8b

# -----------------------------
# Redis
# -----------------------------
# When set, chat history is cached per chatId (session) in Redis for fast fetches.
# Local (running server on your machine): `redis://localhost:6379`
# Docker Compose (server container -> redis container): `redis://redis:6379`
REDIS_URL=redis://localhost:6379
CHAT_HISTORY_CACHE_TTL_SECONDS=3600
CHAT_HISTORY_CACHE_MAX_MESSAGES=200
CHAT_HISTORY_IN_MEMORY_MAX_CHATS=200
